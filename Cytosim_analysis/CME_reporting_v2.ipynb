{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "612e033a",
   "metadata": {},
   "source": [
    "# Cytosim reporting for multiple parameter runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bd292f06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## By Jennifer Hill, 2021\n",
    "## Adapted from Akamatsu et al., 2020, eLife\n",
    "## Report solid, fiber, crosslinker, and arp2/3 positions, numbers, and states from cytosim runs\n",
    "\n",
    "#import packages and libraries\n",
    "import numpy as np\n",
    "from scipy.stats import kde\n",
    "from scipy.ndimage import gaussian_filter\n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "import subprocess\n",
    "from subprocess import Popen\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt  # plotting\n",
    "plt.style.use('seaborn-v0_8-colorblind') # set plot style\n",
    "plt.cool()                          # heatmap color scheme\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cd5e2680",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set variables to define what will be reported\n",
    "timestep = 0.0001\n",
    "report_solid = 'yes'\n",
    "report_fibers = 'yes'\n",
    "report_xlinks = 'no'\n",
    "report_arp = 'no'\n",
    "\n",
    "save_pickles ='yes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8512f1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set output directory where results will be placed (same directory that contains run directories) and working directory\n",
    "output_dir = '/Users/jenniferhill/Documents/tubeZsavio/experiments/longbudtime_1000pN_output_11968314/runs0001/'\n",
    "working_dir = '/Users/jenniferhill/Documents/tubeZsavio/'\n",
    "\n",
    "\n",
    "#set location of report executable\n",
    "report_loc = '/Users/jenniferhill/Documents/tubeZlemmy/bin/report'\n",
    "\n",
    "os.chdir(working_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "72660744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make prefix for figure filenames\n",
    "now = datetime.datetime.now()\n",
    "date = now.strftime('%Y%m%d')\n",
    "pref = date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e56975f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a dataframes and figures folder, in the output folder specific to this set of simulations. will take a lot of space for lots of sets of simulations.\n",
    "    \n",
    "os.chdir(output_dir)\n",
    "\n",
    "if os.path.isdir('figures') == False:\n",
    "    os.mkdir('figures')\n",
    "\n",
    "if os.path.isdir('dataframes') == False:\n",
    "    os.mkdir('dataframes')\n",
    "    \n",
    "os.chdir(working_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "025905fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define dictionaries for datasets and a list for run directories\n",
    "solid_allruns = dict() #bud positions\n",
    "\n",
    "fiber_forces_allruns = dict() #forces on actin filaments\n",
    "fiber_ends_allruns = dict() #positions of plus/minus ends\n",
    "\n",
    "xlinks_allruns = dict() #positions of xlinks and arp2/3s\n",
    "xlinks_state_allruns = dict() #binding state of xlinks\n",
    "xlinks_forces_allruns = dict() #forces on xlinks\n",
    "\n",
    "arp_allruns = dict() #positions of xlinks and arp2/3s\n",
    "arp_branches_allruns = dict() #branching angle of arp2/3s\n",
    "\n",
    "properties_allruns = dict()\n",
    "rundirs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ee9302c1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished reporting run0002_0002\n",
      "finished reporting run0002_0004\n",
      "finished reporting run0002_0003\n",
      "finished reporting run0001_0000\n",
      "finished reporting run0001_0001\n",
      "finished reporting run0000_0001\n",
      "finished reporting run0000_0000\n",
      "finished reporting run0002_0001\n",
      "finished reporting run0002_0000\n",
      "finished reporting run0001_0004\n",
      "finished reporting run0001_0003\n",
      "finished reporting run0001_0002\n",
      "finished reporting run0000_0002\n",
      "finished reporting run0000_0003\n",
      "finished reporting run0000_0004\n"
     ]
    }
   ],
   "source": [
    "for rundir in os.listdir(output_dir):\n",
    "# for rundir in ['xlinks_output_7150999']:\n",
    "     if rundir.startswith('run0'):\n",
    "        os.chdir(output_dir+'/'+rundir)\n",
    "        #change directory to ['xlinks_output_7150999/run****_****']\n",
    "        if report_solid == 'yes':\n",
    "            subprocess.call([report_loc, 'solid', 'output=solid.txt']) #runs the command report_loc (bin/report) with args 'solid' and 'output=solid_jl.txt'\n",
    "            \n",
    "            solid = open('solid.txt', 'r')\n",
    "            solid_allruns[rundir] = solid.readlines() #read the lines of solid.txt into a list called run****_**** and add to the solid_allruns dictionary\n",
    "            solid.close()  \n",
    "        \n",
    "        if report_fibers == 'yes':\n",
    "            subprocess.call([report_loc, 'fiber:forces', 'output=fiber_forces.txt'])\n",
    "            subprocess.call([report_loc, 'fiber:ends', 'output=fiber_ends.txt'])\n",
    "            \n",
    "            fiber_forces = open('fiber_forces.txt', 'r')\n",
    "            fiber_forces_allruns[rundir] = fiber_forces.readlines() #read the lines of fiber_forces.txt into a list called run****_**** and add to the fiber_forces_allruns dictionary\n",
    "            fiber_forces.close()\n",
    "            \n",
    "            fiber_ends = open('fiber_ends.txt', 'r')\n",
    "            fiber_ends_allruns[rundir] = fiber_ends.readlines() #read the lines of fiber_ends.txt into a list called run****_**** and add to the fiber_ends_allruns dictionary\n",
    "            fiber_ends.close()   \n",
    "            \n",
    "        if report_xlinks == 'yes':\n",
    "            subprocess.call([report_loc, 'couple:state', 'output=couple.txt'])\n",
    "            subprocess.call([report_loc, 'couple', 'output=couple_state.txt']) \n",
    "            subprocess.call([report_loc, 'couple:bridge', 'output=couple_forces.txt'])\n",
    "\n",
    "            xlinks = open('couple.txt', 'r')\n",
    "            xlinks_allruns[rundir] = xlinks.readlines()\n",
    "            xlinks.close()\n",
    "            \n",
    "            xlinks_state = open('couple_state.txt', 'r')\n",
    "            xlinks_state_allruns[rundir] = xlinks_state.readlines()\n",
    "            xlinks_state.close()\n",
    "        \n",
    "            xlinks_forces = open('couple_forces.txt', 'r')\n",
    "            xlinks_forces_allruns[rundir] = xlinks_forces.readlines()\n",
    "            xlinks_forces.close()\n",
    "        \n",
    "        if report_arp == 'yes':\n",
    "            subprocess.call([report_loc, 'couple:state', 'output=couple_state.txt']) \n",
    "            subprocess.call([report_loc, 'couple:angle:arp23', 'output=couple_arp_angles.txt'])\n",
    "    \n",
    "            arp = open('couple_state.txt', 'r')\n",
    "            arp_allruns[rundir] = arp.readlines()\n",
    "            arp.close()\n",
    "            \n",
    "            arp_branch = open('couple_arp_angles.txt', 'r')\n",
    "            arp_branches_allruns[rundir] = arp_branch.readlines()\n",
    "            arp_branch.close()\n",
    "        \n",
    "        properties = open('properties.cmo', 'r')\n",
    "        properties_allruns[rundir] = properties.readlines() #read the lines of properties.cmo into a list called run****_**** and add to the properties_allruns dictionary\n",
    "        properties.close()\n",
    "        rundirs.append(rundir) #add the current rundir run****_**** to the list of run directories\n",
    "        print('finished reporting ' + rundir)\n",
    "        os.chdir(working_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ba110a0b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished reading run0002_0002 properties\n",
      "finished reading run0002_0004 properties\n",
      "finished reading run0002_0003 properties\n",
      "finished reading run0001_0000 properties\n",
      "finished reading run0001_0001 properties\n",
      "finished reading run0000_0001 properties\n",
      "finished reading run0000_0000 properties\n",
      "finished reading run0002_0001 properties\n",
      "finished reading run0002_0000 properties\n",
      "finished reading run0001_0004 properties\n",
      "finished reading run0001_0003 properties\n",
      "finished reading run0001_0002 properties\n",
      "finished reading run0000_0002 properties\n",
      "finished reading run0000_0003 properties\n",
      "finished reading run0000_0004 properties\n"
     ]
    }
   ],
   "source": [
    "properties_dict_allruns = dict()\n",
    "\n",
    "for rundir in rundirs:\n",
    "    properties = properties_allruns[rundir] #make a list called properties that is the lines from properties.cmo for that run\n",
    "    properties_dict = dict()\n",
    "    for line in properties:\n",
    "        if '=' in line:\n",
    "            line = line.strip().split(' = ') \n",
    "            #get rid of spaces on either end of the line, convert line into a list with items separated by an = in the line\n",
    "            #ex: ' time       = 9;' strip -> 'time     = 9;' split(' = ') -> ['time    ','9;']\n",
    "            properties_dict[line[0].strip()] = line[-1].strip(';')\n",
    "            #for the item (parameter) in the properties dictionary, add whatever the value is for that run\n",
    "            #ex: line[0].strip() is 'time', the value for time in the properties dictionary is '9'\n",
    "        properties_dict_allruns[rundir] = properties_dict #append the properties dictionary for this run to the dictionary with properties for all runs\n",
    "    print('finished reading ' + rundir + ' properties')   \n",
    "        \n",
    "properties_df = pd.DataFrame.from_dict(properties_dict_allruns, orient = 'index')     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ce4645",
   "metadata": {},
   "source": [
    "## Parse bud positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8ccd87ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished parsing run0002_0002\n",
      "finished parsing run0002_0004\n",
      "finished parsing run0002_0003\n",
      "finished parsing run0001_0000\n",
      "finished parsing run0001_0001\n",
      "finished parsing run0000_0001\n",
      "finished parsing run0000_0000\n",
      "finished parsing run0002_0001\n",
      "finished parsing run0002_0000\n",
      "finished parsing run0001_0004\n",
      "finished parsing run0001_0003\n",
      "finished parsing run0001_0002\n",
      "finished parsing run0000_0002\n",
      "finished parsing run0000_0003\n",
      "finished parsing run0000_0004\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>xpos</th>\n",
       "      <th>ypos</th>\n",
       "      <th>zpos</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run</th>\n",
       "      <th>time</th>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">run0002_0002</th>\n",
       "      <th>0.00</th>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.03</th>\n",
       "      <th>1</th>\n",
       "      <td>-0.002454</td>\n",
       "      <td>0.002268</td>\n",
       "      <td>-0.142357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.06</th>\n",
       "      <th>1</th>\n",
       "      <td>-0.001165</td>\n",
       "      <td>-0.002720</td>\n",
       "      <td>-0.142012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.09</th>\n",
       "      <th>1</th>\n",
       "      <td>-0.002377</td>\n",
       "      <td>-0.004059</td>\n",
       "      <td>-0.141932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.12</th>\n",
       "      <th>1</th>\n",
       "      <td>-0.001786</td>\n",
       "      <td>-0.008891</td>\n",
       "      <td>-0.141941</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          xpos      ypos      zpos\n",
       "run          time id                              \n",
       "run0002_0002 0.00 1   0.000000  0.000000 -0.140000\n",
       "             0.03 1  -0.002454  0.002268 -0.142357\n",
       "             0.06 1  -0.001165 -0.002720 -0.142012\n",
       "             0.09 1  -0.002377 -0.004059 -0.141932\n",
       "             0.12 1  -0.001786 -0.008891 -0.141941"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#parse bud position\n",
    "all_solid_outputs_allruns = pd.DataFrame()\n",
    "\n",
    "if report_solid == 'yes':\n",
    "    solid_outputs_allruns = []\n",
    "    for rundir in rundirs:\n",
    "        all_lines = solid_allruns[rundir] #all_lines is the list of lines read from solid.txt for this run\n",
    "        timepoints = []\n",
    "        outputs = []\n",
    "        for line in all_lines:\n",
    "            line = line.strip() #remove spaces on either end of each line in the list\n",
    "            if line.startswith('%'):\n",
    "                if line.startswith('% time'): #happens first for each timepoint\n",
    "                    time = float(line.split(' ')[-1]) \n",
    "                    timepoints.append(time) #for lines that start with % time, split the line into a list and append the time item (-1) as a float to the timepoints list\n",
    "                    solids = {} #resets solids to empty\n",
    "                elif line.startswith('% end'): #happens last for each timepoint\n",
    "                    df = pd.DataFrame.from_dict(solids, orient = 'index') #for lines that start with % end, make a dataframe from the values in solids (points x y and z)\n",
    "                    outputs.append(df) #append the dataframe of values to the outputs list\n",
    "            elif len(line.split()) > 0: #aka it contains actual data not empty space\n",
    "                [solid_class, solid_id, centroid_x, centroid_y, centroid_z,\n",
    "                point_x, point_y, point_z, idk1, idk2, idk3] = line.split() #split the line into a list of values and assign the values to the associated variables\n",
    "                solids[int(solid_id)] = {'xpos': float(point_x), 'ypos' : float(point_y),\n",
    "                                      'zpos' : float(point_z)}\n",
    "        #creates outputs: list of dataframes containing x, y, and z values for the solid at all time points (one dataframe for each time point)\n",
    "        all_outputs = pd.concat(outputs, keys = timepoints,\n",
    "                                names = ['time', 'id'])\n",
    "        #concatenates all dataframes in the list 'outputs' into a single dataframe with timepoints (one dataframe containing all timepoints)\n",
    "        solid_outputs_allruns.append(all_outputs)\n",
    "        \n",
    "        print( 'finished parsing ' + rundir)\n",
    "\n",
    "    all_solid_outputs_allruns = pd.concat(solid_outputs_allruns, keys = rundirs,\n",
    "                                  names = ['run', 'time', 'id'])\n",
    "all_solid_outputs_allruns.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "593cdf6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#recalibrate bud z position so it starts at z=0 and is given in nm\n",
    "if report_solid == 'yes':\n",
    "    all_solid_outputs_allruns['internalization'] = (all_solid_outputs_allruns['zpos'] + 0.14) * 1000\n",
    "    all_solid_outputs_allruns.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8873ebee",
   "metadata": {},
   "outputs": [],
   "source": [
    "if report_solid == 'yes':\n",
    "    if save_pickles=='yes':\n",
    "        all_solid_outputs_allruns.to_pickle(output_dir+'/dataframes/bud_positions.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16439e23",
   "metadata": {},
   "source": [
    "## Parse forces on all fibers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "019d528e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished parsing run0002_0002\n",
      "finished parsing run0002_0004\n",
      "finished parsing run0002_0003\n",
      "finished parsing run0001_0000\n",
      "finished parsing run0001_0001\n",
      "finished parsing run0000_0001\n",
      "finished parsing run0000_0000\n",
      "finished parsing run0002_0001\n",
      "finished parsing run0002_0000\n",
      "finished parsing run0001_0004\n",
      "finished parsing run0001_0003\n",
      "finished parsing run0001_0002\n",
      "finished parsing run0000_0002\n",
      "finished parsing run0000_0003\n",
      "finished parsing run0000_0004\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>fiber_id</th>\n",
       "      <th>pt_index</th>\n",
       "      <th>xpos</th>\n",
       "      <th>ypos</th>\n",
       "      <th>zpos</th>\n",
       "      <th>xforce</th>\n",
       "      <th>yforce</th>\n",
       "      <th>zforce</th>\n",
       "      <th>tension</th>\n",
       "      <th>force_magnitude</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run</th>\n",
       "      <th>time</th>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">run0002_0002</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">0.0</th>\n",
       "      <th>1_0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.006213</td>\n",
       "      <td>-0.005651</td>\n",
       "      <td>-0.042428</td>\n",
       "      <td>-992.697</td>\n",
       "      <td>945.03000</td>\n",
       "      <td>3199.680</td>\n",
       "      <td>-2757.120</td>\n",
       "      <td>3480.873617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.003728</td>\n",
       "      <td>-0.003391</td>\n",
       "      <td>-0.037457</td>\n",
       "      <td>372.632</td>\n",
       "      <td>-184.49600</td>\n",
       "      <td>306.035</td>\n",
       "      <td>-2125.630</td>\n",
       "      <td>516.285582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001243</td>\n",
       "      <td>-0.001130</td>\n",
       "      <td>-0.032486</td>\n",
       "      <td>289.856</td>\n",
       "      <td>-25.63700</td>\n",
       "      <td>-227.873</td>\n",
       "      <td>-1145.920</td>\n",
       "      <td>369.594184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.001243</td>\n",
       "      <td>0.001130</td>\n",
       "      <td>-0.027514</td>\n",
       "      <td>-271.752</td>\n",
       "      <td>9.17201</td>\n",
       "      <td>368.692</td>\n",
       "      <td>-906.231</td>\n",
       "      <td>458.112504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_4</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.003728</td>\n",
       "      <td>0.003391</td>\n",
       "      <td>-0.022543</td>\n",
       "      <td>-188.260</td>\n",
       "      <td>16.81610</td>\n",
       "      <td>235.229</td>\n",
       "      <td>-524.259</td>\n",
       "      <td>301.757007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       fiber_id  pt_index      xpos      ypos      zpos  \\\n",
       "run          time id                                                      \n",
       "run0002_0002 0.0  1_0         1         0  0.006213 -0.005651 -0.042428   \n",
       "                  1_1         1         1  0.003728 -0.003391 -0.037457   \n",
       "                  1_2         1         2  0.001243 -0.001130 -0.032486   \n",
       "                  1_3         1         3 -0.001243  0.001130 -0.027514   \n",
       "                  1_4         1         4 -0.003728  0.003391 -0.022543   \n",
       "\n",
       "                        xforce     yforce    zforce   tension  force_magnitude  \n",
       "run          time id                                                            \n",
       "run0002_0002 0.0  1_0 -992.697  945.03000  3199.680 -2757.120      3480.873617  \n",
       "                  1_1  372.632 -184.49600   306.035 -2125.630       516.285582  \n",
       "                  1_2  289.856  -25.63700  -227.873 -1145.920       369.594184  \n",
       "                  1_3 -271.752    9.17201   368.692  -906.231       458.112504  \n",
       "                  1_4 -188.260   16.81610   235.229  -524.259       301.757007  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#parse the forces on all fibers\n",
    "all_fiber_forces = pd.DataFrame()\n",
    "\n",
    "if report_fibers == 'yes':\n",
    "    fiber_forces_outputs_allruns = [] #make a dictionary for runs where each run is a dataframe of fiber force outputs from that run\n",
    "    all_fiber_forces = []\n",
    "\n",
    "    for rundir in rundirs:\n",
    "        single_all_lines = fiber_forces_allruns[rundir] #define the item in the fiber_forces_allruns dictionary for run****_****\n",
    "        timepoints = []\n",
    "        outputs = []\n",
    "        for line in single_all_lines:\n",
    "            line = line.strip()\n",
    "            if line.startswith('%'):\n",
    "                if line.startswith('% start'): #add the timepoint to the timepoints list, re-empty singles\n",
    "                    time = float(line.split(' ')[-1])\n",
    "                    timepoints.append(time)\n",
    "                    singles = {}\n",
    "                elif line.startswith('% end'): #make a dataframe from the dictionary of force values, append it to the outputs list\n",
    "                    df = pd.DataFrame.from_dict(singles, orient = 'index')\n",
    "                    outputs.append(df)\n",
    "                    #print('finished parsing ' + rundir + ' timepoint ' + str(time))\n",
    "            elif len(line.split()) > 0: #for lines with data in them, split the data into individual values\n",
    "                [fiber_id, pt_index, xpos, ypos, zpos,\n",
    "                xforce, yforce, zforce, tension] = line.split()\n",
    "                singles[str(fiber_id)+'_'+str(pt_index)] = {'fiber_id' : int(fiber_id),'pt_index' : int(pt_index),\n",
    "                                                            'xpos': float(xpos), 'ypos' : float(ypos), 'zpos': float(zpos),\n",
    "                                                            'xforce' : float(xforce), 'yforce' : float(yforce),\n",
    "                                                            'zforce': float(zforce), 'tension': float(tension)}\n",
    "\n",
    "        #concatenate all outputs dataframes (values for a given timepoint) into a single dataframe with values for all timepoints\n",
    "        all_outputs = pd.concat(outputs, keys = timepoints,\n",
    "                                names = ['time', 'id'])\n",
    "        #magnitude of the force is sqrt of dir. vectors squared\n",
    "        all_outputs['force_magnitude'] = np.sqrt(np.square(all_outputs['xforce']) + \n",
    "                                                  np.square(all_outputs['yforce']) +\n",
    "                                                  np.square(all_outputs['zforce']))\n",
    "        #add the outputs dataframe for the run to the list of dataframes for all runs\n",
    "        fiber_forces_outputs_allruns.append(all_outputs)\n",
    "\n",
    "        print( 'finished parsing ' + rundir)\n",
    "\n",
    "    #concatenate dataframes from each run into a single dataframe with values for all timepoints for all runs\n",
    "    all_fiber_forces = pd.concat(fiber_forces_outputs_allruns, keys = rundirs,\n",
    "                                      names = ['run', 'time', 'id'])\n",
    "all_fiber_forces.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "27339a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if report_fibers == 'yes':\n",
    "    if save_pickles=='yes':\n",
    "        all_fiber_forces.to_pickle(output_dir+'/dataframes/actin_positions_forces.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69a86d1",
   "metadata": {},
   "source": [
    "## Parse fiber end positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "60bf1fcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished parsing run0002_0002\n",
      "finished parsing run0002_0004\n",
      "finished parsing run0002_0003\n",
      "finished parsing run0001_0000\n",
      "finished parsing run0001_0001\n",
      "finished parsing run0000_0001\n",
      "finished parsing run0000_0000\n",
      "finished parsing run0002_0001\n",
      "finished parsing run0002_0000\n",
      "finished parsing run0001_0004\n",
      "finished parsing run0001_0003\n",
      "finished parsing run0001_0002\n",
      "finished parsing run0000_0002\n",
      "finished parsing run0000_0003\n",
      "finished parsing run0000_0004\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>fiber_id</th>\n",
       "      <th>length</th>\n",
       "      <th>minus_state</th>\n",
       "      <th>minus_xpos</th>\n",
       "      <th>minus_ypos</th>\n",
       "      <th>minus_zpos</th>\n",
       "      <th>minus_xdir</th>\n",
       "      <th>minus_ydir</th>\n",
       "      <th>minus_zdir</th>\n",
       "      <th>plus_state</th>\n",
       "      <th>plus_xpos</th>\n",
       "      <th>plus_ypos</th>\n",
       "      <th>plus_zpos</th>\n",
       "      <th>plus_xdir</th>\n",
       "      <th>plus_ydir</th>\n",
       "      <th>plus_zdir</th>\n",
       "      <th>plus_rpos</th>\n",
       "      <th>zdir_deg_flip90</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run</th>\n",
       "      <th>time</th>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">run0002_0002</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">0.00</th>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>1</td>\n",
       "      <td>0.006213</td>\n",
       "      <td>-0.005651</td>\n",
       "      <td>-0.042428</td>\n",
       "      <td>-0.414228</td>\n",
       "      <td>0.376727</td>\n",
       "      <td>0.828548</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.006213</td>\n",
       "      <td>0.005651</td>\n",
       "      <td>-0.017572</td>\n",
       "      <td>-0.414228</td>\n",
       "      <td>0.376727</td>\n",
       "      <td>0.828548</td>\n",
       "      <td>0.008399</td>\n",
       "      <td>-55.949870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.03</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.005590</td>\n",
       "      <td>-0.002175</td>\n",
       "      <td>-0.043749</td>\n",
       "      <td>0.372676</td>\n",
       "      <td>0.144990</td>\n",
       "      <td>0.916565</td>\n",
       "      <td>1</td>\n",
       "      <td>0.005590</td>\n",
       "      <td>0.002175</td>\n",
       "      <td>-0.016251</td>\n",
       "      <td>0.372676</td>\n",
       "      <td>0.144989</td>\n",
       "      <td>0.916565</td>\n",
       "      <td>0.005998</td>\n",
       "      <td>-66.428965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.03</td>\n",
       "      <td>1</td>\n",
       "      <td>0.011793</td>\n",
       "      <td>-0.009208</td>\n",
       "      <td>-0.031064</td>\n",
       "      <td>-0.786190</td>\n",
       "      <td>0.613896</td>\n",
       "      <td>0.070964</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.011793</td>\n",
       "      <td>0.009208</td>\n",
       "      <td>-0.028935</td>\n",
       "      <td>-0.786190</td>\n",
       "      <td>0.613896</td>\n",
       "      <td>0.070964</td>\n",
       "      <td>0.014962</td>\n",
       "      <td>-4.069347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">0.03</th>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.06</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.004595</td>\n",
       "      <td>0.001345</td>\n",
       "      <td>-0.031214</td>\n",
       "      <td>-0.738214</td>\n",
       "      <td>-0.635475</td>\n",
       "      <td>0.226301</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.048989</td>\n",
       "      <td>-0.036680</td>\n",
       "      <td>-0.017681</td>\n",
       "      <td>-0.743211</td>\n",
       "      <td>-0.631615</td>\n",
       "      <td>0.220681</td>\n",
       "      <td>0.061199</td>\n",
       "      <td>-12.749035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.06</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.002184</td>\n",
       "      <td>0.004524</td>\n",
       "      <td>-0.031234</td>\n",
       "      <td>0.015173</td>\n",
       "      <td>0.974127</td>\n",
       "      <td>0.225490</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.001472</td>\n",
       "      <td>0.062899</td>\n",
       "      <td>-0.017385</td>\n",
       "      <td>0.010550</td>\n",
       "      <td>0.971414</td>\n",
       "      <td>0.237160</td>\n",
       "      <td>0.062916</td>\n",
       "      <td>-13.718982</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      fiber_id  length  minus_state  minus_xpos  minus_ypos  \\\n",
       "run          time id                                                          \n",
       "run0002_0002 0.00 1          1    0.03            1    0.006213   -0.005651   \n",
       "                  2          2    0.03            1   -0.005590   -0.002175   \n",
       "                  3          3    0.03            1    0.011793   -0.009208   \n",
       "             0.03 2          2    0.06            1   -0.004595    0.001345   \n",
       "                  3          3    0.06            1   -0.002184    0.004524   \n",
       "\n",
       "                      minus_zpos  minus_xdir  minus_ydir  minus_zdir  \\\n",
       "run          time id                                                   \n",
       "run0002_0002 0.00 1    -0.042428   -0.414228    0.376727    0.828548   \n",
       "                  2    -0.043749    0.372676    0.144990    0.916565   \n",
       "                  3    -0.031064   -0.786190    0.613896    0.070964   \n",
       "             0.03 2    -0.031214   -0.738214   -0.635475    0.226301   \n",
       "                  3    -0.031234    0.015173    0.974127    0.225490   \n",
       "\n",
       "                      plus_state  plus_xpos  plus_ypos  plus_zpos  plus_xdir  \\\n",
       "run          time id                                                           \n",
       "run0002_0002 0.00 1            1  -0.006213   0.005651  -0.017572  -0.414228   \n",
       "                  2            1   0.005590   0.002175  -0.016251   0.372676   \n",
       "                  3            1  -0.011793   0.009208  -0.028935  -0.786190   \n",
       "             0.03 2            1  -0.048989  -0.036680  -0.017681  -0.743211   \n",
       "                  3            1  -0.001472   0.062899  -0.017385   0.010550   \n",
       "\n",
       "                      plus_ydir  plus_zdir  plus_rpos  zdir_deg_flip90  \n",
       "run          time id                                                    \n",
       "run0002_0002 0.00 1    0.376727   0.828548   0.008399       -55.949870  \n",
       "                  2    0.144989   0.916565   0.005998       -66.428965  \n",
       "                  3    0.613896   0.070964   0.014962        -4.069347  \n",
       "             0.03 2   -0.631615   0.220681   0.061199       -12.749035  \n",
       "                  3    0.971414   0.237160   0.062916       -13.718982  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#parse fiber end positions\n",
    "all_fiber_ends = pd.DataFrame()\n",
    "\n",
    "if report_fibers == 'yes':\n",
    "    fiber_ends_outputs_allruns = []\n",
    "    for rundir in rundirs:\n",
    "        single_all_lines = fiber_ends_allruns[rundir] #define the item in the fiber_ends_allruns dictionary for run****_****\n",
    "        timepoints = []\n",
    "        outputs = []\n",
    "        for line in single_all_lines:\n",
    "            line = line.strip()\n",
    "            if line.startswith('%'): \n",
    "                if line.startswith('% time'): #add the timepoint to the timepoints list, re-empty singles\n",
    "                    time = float(line.split(' ')[-1])\n",
    "                    timepoints.append(time)\n",
    "                    singles = {}\n",
    "                elif line.startswith('% end'): #make a dataframe from the dictionary of endpoint values, append it to the outputs list\n",
    "                    df = pd.DataFrame.from_dict(singles, orient = 'index')\n",
    "                    outputs.append(df)\n",
    "                    # print 'finished parsing ' + rundir + ' timepoint ' + str(time)\n",
    "            elif len(line.split()) > 0: #for lines with data in them, split the data into individual values\n",
    "                [fiber_class, fiber_id, length, minus_state, minus_xpos, minus_ypos, minus_zpos,\n",
    "                minus_xdir, minus_ydir, minus_zdir, plus_state, plus_xpos, plus_ypos,\n",
    "                plus_zpos, plus_xdir, plus_ydir, plus_zdir] = line.split()\n",
    "                singles[int(fiber_id)] = {'fiber_id' : int(fiber_id), 'length':float(length),\n",
    "                                          'minus_state':int(minus_state), 'minus_xpos':float(minus_xpos),\n",
    "                                          'minus_ypos':float(minus_ypos), 'minus_zpos':float(minus_zpos),\n",
    "                                          'minus_xdir':float(minus_xdir), 'minus_ydir':float(minus_ydir),\n",
    "                                          'minus_zdir':float(minus_zdir), 'plus_state':int(plus_state),\n",
    "                                          'plus_xpos':float(plus_xpos), 'plus_ypos':float(plus_ypos),\n",
    "                                          'plus_zpos':float(plus_zpos), 'plus_xdir':float(plus_xdir),\n",
    "                                          'plus_ydir':float(plus_ydir), 'plus_zdir':float(plus_zdir)}\n",
    "\n",
    "        #concatenate all outputs dataframes (values for a given timepoint) into a single dataframe with values for all timepoints\n",
    "        all_outputs = pd.concat(outputs, keys = timepoints,\n",
    "                            names = ['time', 'id'])\n",
    "        #convert plus end position in cartesian coords to polar coords (just r)\n",
    "        all_outputs['plus_rpos'] = np.sqrt(np.square(all_outputs['plus_xpos']) +\n",
    "                                      np.square(all_outputs['plus_ypos']))\n",
    "\n",
    "        #convert zdir to degrees, oriented vertically such that +90 is POSITIVE orientation and -90 is negative orientation\n",
    "        all_outputs['zdir_deg_flip90'] = np.degrees((np.arccos(all_outputs['plus_zdir'])-(np.pi)/2))\n",
    "\n",
    "        #add the outputs dataframe for the run to the list of dataframes for all runs\n",
    "        fiber_ends_outputs_allruns.append(all_outputs)\n",
    "\n",
    "        print( 'finished parsing ' + rundir)\n",
    "\n",
    "    #concatenate dataframes from each run into a single dataframe with values for all timepoints for all runs\n",
    "    all_fiber_ends = pd.concat(fiber_ends_outputs_allruns, keys = rundirs,\n",
    "                                  names = ['run', 'time', 'id'])\n",
    "all_fiber_ends.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dca8e1d",
   "metadata": {},
   "source": [
    "## Recalibrate fiber end positions\n",
    "### Center X, Y, Z, R positions around bud position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f3c5fdee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>fiber_id</th>\n",
       "      <th>length</th>\n",
       "      <th>minus_state</th>\n",
       "      <th>minus_xpos</th>\n",
       "      <th>minus_ypos</th>\n",
       "      <th>minus_zpos</th>\n",
       "      <th>minus_xdir</th>\n",
       "      <th>minus_ydir</th>\n",
       "      <th>minus_zdir</th>\n",
       "      <th>plus_state</th>\n",
       "      <th>...</th>\n",
       "      <th>plus_rpos</th>\n",
       "      <th>zdir_deg_flip90</th>\n",
       "      <th>minus_xpos_recal</th>\n",
       "      <th>minus_ypos_recal</th>\n",
       "      <th>minus_zpos_recal</th>\n",
       "      <th>plus_xpos_recal</th>\n",
       "      <th>plus_ypos_recal</th>\n",
       "      <th>plus_zpos_recal</th>\n",
       "      <th>plus_rpos_recal</th>\n",
       "      <th>minus_rpos_recal</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run</th>\n",
       "      <th>time</th>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">run0002_0002</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">0.00</th>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>1</td>\n",
       "      <td>0.006213</td>\n",
       "      <td>-0.005651</td>\n",
       "      <td>-0.042428</td>\n",
       "      <td>-0.414228</td>\n",
       "      <td>0.376727</td>\n",
       "      <td>0.828548</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008399</td>\n",
       "      <td>-55.949870</td>\n",
       "      <td>6.21342</td>\n",
       "      <td>-5.65091</td>\n",
       "      <td>12.4282</td>\n",
       "      <td>-6.21342</td>\n",
       "      <td>5.65091</td>\n",
       "      <td>-12.4282</td>\n",
       "      <td>8.398772</td>\n",
       "      <td>8.398772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.03</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.005590</td>\n",
       "      <td>-0.002175</td>\n",
       "      <td>-0.043749</td>\n",
       "      <td>0.372676</td>\n",
       "      <td>0.144990</td>\n",
       "      <td>0.916565</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005998</td>\n",
       "      <td>-66.428965</td>\n",
       "      <td>-5.59014</td>\n",
       "      <td>-2.17484</td>\n",
       "      <td>13.7485</td>\n",
       "      <td>5.59014</td>\n",
       "      <td>2.17484</td>\n",
       "      <td>-13.7485</td>\n",
       "      <td>5.998299</td>\n",
       "      <td>5.998299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.03</td>\n",
       "      <td>1</td>\n",
       "      <td>0.011793</td>\n",
       "      <td>-0.009208</td>\n",
       "      <td>-0.031064</td>\n",
       "      <td>-0.786190</td>\n",
       "      <td>0.613896</td>\n",
       "      <td>0.070964</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014962</td>\n",
       "      <td>-4.069347</td>\n",
       "      <td>11.79290</td>\n",
       "      <td>-9.20845</td>\n",
       "      <td>1.0645</td>\n",
       "      <td>-11.79290</td>\n",
       "      <td>9.20845</td>\n",
       "      <td>-1.0645</td>\n",
       "      <td>14.962220</td>\n",
       "      <td>14.962220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">0.03</th>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.06</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.004595</td>\n",
       "      <td>0.001345</td>\n",
       "      <td>-0.031214</td>\n",
       "      <td>-0.738214</td>\n",
       "      <td>-0.635475</td>\n",
       "      <td>0.226301</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.061199</td>\n",
       "      <td>-12.749035</td>\n",
       "      <td>-2.14094</td>\n",
       "      <td>-0.92300</td>\n",
       "      <td>1.2137</td>\n",
       "      <td>-46.53556</td>\n",
       "      <td>-38.94820</td>\n",
       "      <td>-12.3193</td>\n",
       "      <td>60.683776</td>\n",
       "      <td>2.331427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.06</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.002184</td>\n",
       "      <td>0.004524</td>\n",
       "      <td>-0.031234</td>\n",
       "      <td>0.015173</td>\n",
       "      <td>0.974127</td>\n",
       "      <td>0.225490</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062916</td>\n",
       "      <td>-13.718982</td>\n",
       "      <td>0.27007</td>\n",
       "      <td>2.25627</td>\n",
       "      <td>1.2343</td>\n",
       "      <td>0.98194</td>\n",
       "      <td>60.63070</td>\n",
       "      <td>-12.6154</td>\n",
       "      <td>60.638651</td>\n",
       "      <td>2.272376</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      fiber_id  length  minus_state  minus_xpos  minus_ypos  \\\n",
       "run          time id                                                          \n",
       "run0002_0002 0.00 1          1    0.03            1    0.006213   -0.005651   \n",
       "                  2          2    0.03            1   -0.005590   -0.002175   \n",
       "                  3          3    0.03            1    0.011793   -0.009208   \n",
       "             0.03 2          2    0.06            1   -0.004595    0.001345   \n",
       "                  3          3    0.06            1   -0.002184    0.004524   \n",
       "\n",
       "                      minus_zpos  minus_xdir  minus_ydir  minus_zdir  \\\n",
       "run          time id                                                   \n",
       "run0002_0002 0.00 1    -0.042428   -0.414228    0.376727    0.828548   \n",
       "                  2    -0.043749    0.372676    0.144990    0.916565   \n",
       "                  3    -0.031064   -0.786190    0.613896    0.070964   \n",
       "             0.03 2    -0.031214   -0.738214   -0.635475    0.226301   \n",
       "                  3    -0.031234    0.015173    0.974127    0.225490   \n",
       "\n",
       "                      plus_state  ...  plus_rpos  zdir_deg_flip90  \\\n",
       "run          time id              ...                               \n",
       "run0002_0002 0.00 1            1  ...   0.008399       -55.949870   \n",
       "                  2            1  ...   0.005998       -66.428965   \n",
       "                  3            1  ...   0.014962        -4.069347   \n",
       "             0.03 2            1  ...   0.061199       -12.749035   \n",
       "                  3            1  ...   0.062916       -13.718982   \n",
       "\n",
       "                      minus_xpos_recal  minus_ypos_recal  minus_zpos_recal  \\\n",
       "run          time id                                                         \n",
       "run0002_0002 0.00 1            6.21342          -5.65091           12.4282   \n",
       "                  2           -5.59014          -2.17484           13.7485   \n",
       "                  3           11.79290          -9.20845            1.0645   \n",
       "             0.03 2           -2.14094          -0.92300            1.2137   \n",
       "                  3            0.27007           2.25627            1.2343   \n",
       "\n",
       "                      plus_xpos_recal  plus_ypos_recal  plus_zpos_recal  \\\n",
       "run          time id                                                      \n",
       "run0002_0002 0.00 1          -6.21342          5.65091         -12.4282   \n",
       "                  2           5.59014          2.17484         -13.7485   \n",
       "                  3         -11.79290          9.20845          -1.0645   \n",
       "             0.03 2         -46.53556        -38.94820         -12.3193   \n",
       "                  3           0.98194         60.63070         -12.6154   \n",
       "\n",
       "                      plus_rpos_recal  minus_rpos_recal  \n",
       "run          time id                                     \n",
       "run0002_0002 0.00 1          8.398772          8.398772  \n",
       "                  2          5.998299          5.998299  \n",
       "                  3         14.962220         14.962220  \n",
       "             0.03 2         60.683776          2.331427  \n",
       "                  3         60.638651          2.272376  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#bud moves in x, y, and z during simulation, recalculate fiber x, y, and z positions to be relative to bud position\n",
    "all_fiber_ends_recal = pd.DataFrame()\n",
    "\n",
    "if report_fibers == 'yes' and report_solid == 'yes':\n",
    "    all_fiber_ends_recal = pd.merge(all_fiber_ends.reset_index(), all_solid_outputs_allruns.reset_index(), on = ['run','time'])\n",
    "\n",
    "    all_fiber_ends_recal['minus_xpos_recal'] = (all_fiber_ends_recal['minus_xpos'] - all_fiber_ends_recal['xpos'])*1000\n",
    "    all_fiber_ends_recal['minus_ypos_recal'] = (all_fiber_ends_recal['minus_ypos'] - all_fiber_ends_recal['ypos'])*1000\n",
    "    all_fiber_ends_recal['minus_zpos_recal'] = (all_fiber_ends_recal['minus_zpos'] + 0.03)*(-1000)\n",
    "\n",
    "    all_fiber_ends_recal['plus_xpos_recal'] = (all_fiber_ends_recal['plus_xpos'] - all_fiber_ends_recal['xpos'])*1000\n",
    "    all_fiber_ends_recal['plus_ypos_recal'] = (all_fiber_ends_recal['plus_ypos'] - all_fiber_ends_recal['ypos'])*1000\n",
    "    all_fiber_ends_recal['plus_zpos_recal'] = (all_fiber_ends_recal['plus_zpos'] +0.03)*(-1000)\n",
    "\n",
    "    all_fiber_ends_recal['plus_rpos_recal'] = np.sqrt(np.square(all_fiber_ends_recal['plus_xpos_recal']) +\n",
    "                                      np.square(all_fiber_ends_recal['plus_ypos_recal']))\n",
    "\n",
    "    all_fiber_ends_recal['minus_rpos_recal'] = np.sqrt(np.square(all_fiber_ends_recal['minus_xpos_recal']) +\n",
    "                                      np.square(all_fiber_ends_recal['minus_ypos_recal']))\n",
    "\n",
    "    all_fiber_ends_recal = all_fiber_ends_recal.drop(columns=['id_y', 'xpos', 'ypos', 'zpos', 'internalization'])\n",
    "    all_fiber_ends_recal = all_fiber_ends_recal.rename(index=str, columns={\"id_x\": \"id\"})\n",
    "    all_fiber_ends_recal = all_fiber_ends_recal.set_index(['run', 'time', 'id'])\n",
    "\n",
    "all_fiber_ends_recal.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "53b8f08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_pickles=='yes':\n",
    "    if report_fibers == 'yes' and report_solid == 'yes':\n",
    "        all_fiber_ends_recal.to_pickle(output_dir+'/dataframes/actin_plus_minus_ends_recal.pkl')\n",
    "    elif report_fibers == 'yes':\n",
    "        all_fiber_ends.to_pickle(output_dir+'/dataframes/actin_plus_minus_ends.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "fc23627a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bud_positions, internalization: true z position in nm of tip of bud, starts at z=0 and increases\n",
    "#all_fiber_ends_recal, x,y,z,rpos_recal: true x,y,z,r position in nm of plus/minus ends of actin filaments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4200aa7b",
   "metadata": {},
   "source": [
    "## Report and parse crosslinkers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "164b622c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#parse crosslinker positions\n",
    "all_couple_xlinks = pd.DataFrame()\n",
    "\n",
    "if report_xlinks == 'yes':\n",
    "    couple_xlinks_outputs_allruns = [] #make a dictionary for runs where each run is a dataframe of xlinks outputs from that run\n",
    "    for rundir in rundirs:\n",
    "        couple_all_lines = xlinks_allruns[rundir] #define couple_all_lines as the list of lines for run****_**** from xlinks_allruns dictionary\n",
    "        timepoints = []\n",
    "        outputs = []\n",
    "        for line in couple_all_lines:\n",
    "            line = line.strip()\n",
    "            if line.startswith('%'): #see same lines from parsing internalization\n",
    "                if line.startswith('% time'):\n",
    "                    time = float(line.split(' ')[-1])\n",
    "                    timepoints.append(time)\n",
    "                    couples_xlinks = {} #resets couples_xlinks to empty\n",
    "                elif line.startswith('% end'):\n",
    "                    df = pd.DataFrame.from_dict(couples_xlinks, orient = 'index') #creates a dataframe consisting of all the lines from the last time point\n",
    "                    outputs.append(df) #adds the dataframe to the outputs list\n",
    "                    # print 'finished parsing ' + rundir + ' timepoint ' + str(time)\n",
    "            elif line.startswith('2'): #line is for a couple of class 2, aka crosslinker\n",
    "                [couple_class, couple_id, bound_state, xpos, ypos, zpos, id_fiber1, abscissa1, id_fiber2, abscissa2] = line.split()\n",
    "                couples_xlinks[int(couple_id)] = {'bound_state' : int(bound_state), 'arp_id': int(couple_id), \n",
    "                                               'xpos': float(xpos), 'ypos': float(ypos), 'zpos': float(zpos), \n",
    "                                               'id_fiber1': int(id_fiber1), 'abscissa1': float(abscissa1), 'id_fiber2': int(id_fiber2), 'abscissa2': float(abscissa2)}\n",
    "                #for the list item in couples_xlinks defined by the couple_id, assign the values to the given names\n",
    "\n",
    "        #convert the list of outputs dataframes to a single dataframe with xlinks outputs for each timepoint\n",
    "        all_outputs = pd.concat(outputs, keys = timepoints,\n",
    "                            names = ['time', 'id'])\n",
    "\n",
    "        #add the dataframe with outputs for all time points for run****_**** to the list of outputs for each run\n",
    "        couple_xlinks_outputs_allruns.append(all_outputs)\n",
    "\n",
    "        print( 'finished parsing ' + rundir)\n",
    "\n",
    "    #convert the list of outputs for each run into a single dataframe containing all runs\n",
    "    all_couple_xlinks = pd.concat(couple_xlinks_outputs_allruns, keys = rundirs,\n",
    "                                  names = ['run', 'time', 'id'])\n",
    "\n",
    "all_couple_xlinks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4ee2f260",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a second dataframe for singly bound crosslinkers only\n",
    "singly_bound_xlinks = pd.DataFrame()\n",
    "\n",
    "if report_xlinks == 'yes':\n",
    "    singly_bound = []\n",
    "\n",
    "    #id_fiber is zero when xlink hand is not bound to a fiber, singly bound will have one id = 0 and the other id =/= 0\n",
    "    singly_bound.append(all_couple_xlinks.loc[np.logical_and(all_couple_xlinks['id_fiber1'] != 0, all_couple_xlinks['id_fiber2'] == 0)])\n",
    "    #append the dataframe made up of the rows from all_couple_xlinks where id_fiber1 =/= 0 and id_fiber2 = 0 to the list singly_bound\n",
    "    singly_bound.append(all_couple_xlinks.loc[np.logical_and(all_couple_xlinks['id_fiber1'] == 0, all_couple_xlinks['id_fiber2'] != 0)])\n",
    "    #append the dataframe made up of the rows from all_couple_xlinks where id_fiber1 = 0 and id_fiber2 =/= 0 to the list singly_bound\n",
    "\n",
    "    #concatenate the two dataframes in the list together and sort by the run index (sorts all other indices as well)\n",
    "    singly_bound_xlinks = pd.concat(singly_bound)\n",
    "    singly_bound_xlinks = singly_bound_xlinks.sort_index()\n",
    "singly_bound_xlinks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8271906c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a third dataframe for active crosslinkers only\n",
    "active_xlinks = pd.DataFrame()\n",
    "\n",
    "if report_xlinks == 'yes':\n",
    "    active_xlinks = pd.DataFrame()\n",
    "    active_xlinks = all_couple_xlinks.loc[np.logical_and(all_couple_xlinks['id_fiber1'] != 0, all_couple_xlinks['id_fiber2'] != 0)]\n",
    "    #doubly bound will have both fiber_ids =/= 0\n",
    "active_xlinks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d2af4d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save to pickles\n",
    "if save_pickles=='yes':\n",
    "    singly_bound_xlinks.to_pickle(output_dir+'/dataframes/singly_bound_xlinks.pkl')\n",
    "    active_xlinks.to_pickle(output_dir+'/dataframes/active_xlinks.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "350fe481",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#parse crosslinker states\n",
    "all_couple_xlinks_state = pd.DataFrame()\n",
    "\n",
    "if report_xlinks == 'yes':\n",
    "    xlinks_state_outputs_allruns = [] #make a dictionary for runs where each run is a dataframe of xlinks outputs from that run\n",
    "    for rundir in rundirs:\n",
    "        couple_all_lines = xlinks_state_allruns[rundir] #define couple_all_lines as the list of lines for run****_**** from xlinks_state_allruns dictionary\n",
    "        timepoints = []\n",
    "        outputs = []\n",
    "        for line in couple_all_lines:\n",
    "            line = line.strip()\n",
    "            if line.startswith('%'): #see same lines from parsing internalization\n",
    "                if line.startswith('% time'):\n",
    "                    time = float(line.split(' ')[-1])\n",
    "                    timepoints.append(time)\n",
    "                    couples_xlinks = {} #resets couples_xlinks dict to empty\n",
    "                elif line.startswith('% end'):\n",
    "                    df = pd.DataFrame.from_dict(couples_xlinks, orient = 'index') #creates a dataframe consisting of crosslinker line from the last time point\n",
    "                    outputs.append(df) #adds the dataframe to the outputs list\n",
    "                    # print 'finished parsing ' + rundir + ' timepoint ' + str(time)\n",
    "            elif line.startswith('crosslinker'): #line is for a crosslinkers not arp2/3\n",
    "                [couple, total, active, FF, AF, FA, AA] = line.split()\n",
    "                couples_xlinks[(0)] = {'couple' : str(couple), 'total': int(total), \n",
    "                                               'active': int(active), 'FF': int(FF), 'AF': int(AF), \n",
    "                                               'FA': int(FA), 'AA': int(AA)}\n",
    "                #for the dict item in couples_xlinks defined by the couple_id, assign the values to the given names\n",
    "\n",
    "        #convert the list of outputs dataframes to a single dataframe with xlinks outputs for each timepoint\n",
    "        all_outputs = pd.concat(outputs, keys = timepoints,\n",
    "                            names = ['time', 'id'])\n",
    "\n",
    "        #generate a bound column with the total number of crosslinkers bound in the network\n",
    "        all_outputs['bound'] = all_outputs['AF'] + all_outputs['FA'] + all_outputs['AA']\n",
    "\n",
    "        #add the dataframe with outputs for all time points for run****_**** to the list of outputs for each run\n",
    "        xlinks_state_outputs_allruns.append(all_outputs)\n",
    "\n",
    "        print( 'finished parsing ' + rundir)\n",
    "\n",
    "    #convert the list of outputs for each run into a single dataframe containing all runs\n",
    "    all_couple_xlinks_state = pd.concat(xlinks_state_outputs_allruns, keys = rundirs,\n",
    "                                  names = ['run', 'time', 'id'])\n",
    "\n",
    "all_couple_xlinks_state.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "886d099c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#parse crosslinker forces\n",
    "all_couple_xlinks_force = pd.DataFrame()\n",
    "\n",
    "if report_xlinks == 'yes':\n",
    "    xlinks_force_outputs_allruns = [] #make a dictionary for runs where each run is a dataframe of xlinks outputs from that run\n",
    "    for rundir in rundirs:\n",
    "        couple_all_lines = xlinks_forces_allruns[rundir] #define couple_all_lines as the list of lines for run****_**** from xlinks_forces_allruns dictionary\n",
    "        timepoints = []\n",
    "        outputs = []\n",
    "        for line in couple_all_lines:\n",
    "            line = line.strip()\n",
    "            if line.startswith('%'): #see same lines from parsing internalization\n",
    "                if line.startswith('% time'):\n",
    "                    time = float(line.split(' ')[-1])\n",
    "                    timepoints.append(time)\n",
    "                    couples_xlinks = {} #resets couples_xlinks dict to empty\n",
    "                elif line.startswith('% end'):\n",
    "                    df = pd.DataFrame.from_dict(couples_xlinks, orient = 'index') #creates a dataframe consisting of crosslinker line from the last time point\n",
    "                    outputs.append(df) #adds the dataframe to the outputs list\n",
    "                    # print 'finished parsing ' + rundir + ' timepoint ' + str(time)\n",
    "            elif line.startswith('2'): #line is for a couple of class crosslinker\n",
    "                [couple_class, couple_id, id_fiber1, abscissa1, id_fiber_2, abscissa2, force_nrm, \n",
    "                 xpos_hand1, ypos_hand1, zpos_hand1, xpos_hand2, ypos_hand2, zpos_hand2] = line.split()\n",
    "                couples_xlinks[int(couple_id)] = {'couple_class' : int(couple_class), 'couple_id': int(couple_id), \n",
    "                                               'id_fiber1': int(id_fiber1), 'abscissa1': float(abscissa1), 'id_fiber2': int(id_fiber2), 'abscissa2': float(abscissa2), \n",
    "                                               'force_nrm': float(force_nrm), 'xpos_hand1': float(xpos_hand1), 'ypos_hand1': float(ypos_hand1), 'zpos_hand1': float(zpos_hand1),\n",
    "                                                 'xpos_hand2': float(xpos_hand2), 'ypos_hand2': float(ypos_hand2), 'zpos_hand2': float(zpos_hand2),}\n",
    "                #for the dict item in couples_xlinks defined by the couple_id, assign the values to the given names\n",
    "\n",
    "        #convert the list of outputs dataframes to a single dataframe with xlinks outputs for each timepoint\n",
    "        all_outputs = pd.concat(outputs, keys = timepoints,\n",
    "                            names = ['time', 'id'])\n",
    "\n",
    "        #add the dataframe with outputs for all time points for run****_**** to the list of outputs for each run\n",
    "        xlinks_force_outputs_allruns.append(all_outputs)\n",
    "\n",
    "        print( 'finished parsing ' + rundir)\n",
    "\n",
    "    #convert the list of outputs for each run into a single dataframe containing all runs\n",
    "    all_couple_xlinks_force = pd.concat(xlinks_force_outputs_allruns, keys = rundirs,\n",
    "                                  names = ['run', 'time', 'id'])\n",
    "\n",
    "all_couple_xlinks_force.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8bec92d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#merge xlinks forces to active_xlinks\n",
    "if report_xlinks == 'yes':\n",
    "    force_nrm = all_couple_xlinks_force.loc[:,('force_nrm')]\n",
    "    active_xlinks[\"force_nrm\"] = force_nrm\n",
    "active_xlinks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "6ab76751",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save to pickles\n",
    "if report_xlinks == 'yes':\n",
    "    if save_pickles=='yes':\n",
    "        all_couple_xlinks_state.to_pickle(output_dir+'/dataframes/xlinks_state.pkl')\n",
    "        all_couple_xlinks.to_pickle(output_dir+'/dataframes/all_xlinks.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ca3187",
   "metadata": {},
   "source": [
    "## Report and parse Arp2/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0a81834c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#parse the positions of all and bound arp2/3s\n",
    "all_couple_arp = pd.DataFrame()\n",
    "\n",
    "if report_arp == 'yes':\n",
    "    couple_arp_outputs_allruns = [] #make a dictionary for runs where each run is a dataframe of arp2/3 outputs from that run\n",
    "    for rundir in rundirs:\n",
    "        couple_all_lines = arp_allruns[rundir] #define couple_all_runs as the list of lines for run****_**** from arp_allruns dictionary\n",
    "        timepoints = []\n",
    "        outputs = []\n",
    "        for line in couple_all_lines:\n",
    "            line = line.strip()\n",
    "            if line.startswith('%'): #see same lines from parsing internalization\n",
    "                if line.startswith('% time'):\n",
    "                    time = float(line.split(' ')[-1])\n",
    "                    timepoints.append(time)\n",
    "                    couples_arp = {} #resets couples_arp to empty\n",
    "                elif line.startswith('% end'):\n",
    "                    df = pd.DataFrame.from_dict(couples_arp, orient = 'index') #creates a dataframe consisting of all the lines from the last time point\n",
    "                    outputs.append(df) #adds the dataframe to the outputs list\n",
    "                    # print 'finished parsing ' + rundir + ' timepoint ' + str(time)\n",
    "            elif line.startswith('1'): #line is for a couple of class 1, aka arp2/3\n",
    "                [couple_class, couple_id, bound_state, xpos, ypos, zpos, id_fiber1, abscissa1, id_fiber2, abscissa2] = line.split()\n",
    "                couples_arp[int(couple_id)] = {'bound_state' : int(bound_state), 'arp_id': int(couple_id), \n",
    "                                               'xpos': float(xpos), 'ypos': float(ypos), 'zpos': float(zpos), \n",
    "                                               'id_fiber1': int(id_fiber1), 'abscissa1': float(abscissa1), 'id_fiber2': int(id_fiber2), 'abscissa2': float(abscissa2)}\n",
    "                #for the list item in couples_arp defined by the couple_id, assign the values to the given names\n",
    "\n",
    "        #convert the list of outputs dataframes to a single dataframe with arp2/3 outputs for each timepoint\n",
    "        all_outputs = pd.concat(outputs, keys = timepoints,\n",
    "                            names = ['time', 'id'])\n",
    "\n",
    "        #add the dataframe with outputs for all time points for run****_**** to the list of outputs for each run\n",
    "        couple_arp_outputs_allruns.append(all_outputs)\n",
    "\n",
    "        print( 'finished parsing ' + rundir)\n",
    "\n",
    "    #convert the list of outputs for each run into a single dataframe containing all runs\n",
    "    all_couple_arp = pd.concat(couple_arp_outputs_allruns, keys = rundirs,\n",
    "                                  names = ['run', 'time', 'id'])\n",
    "\n",
    "    #create a second dataframe for bound arp2/3 only\n",
    "    bound_arp = all_couple_arp.loc[all_couple_arp['id_fiber1'] != 0] #id_fiber1 is zero when arp2/3 is not bound to a fiber\n",
    "all_couple_arp.head() #show the first few lines fo the all_couple_arp dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a611c85e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#parse arp2/3 branch angles (angle in cos theta)\n",
    "all_arp_combined = pd.DataFrame()\n",
    "\n",
    "if report_arp == 'yes':\n",
    "    couple_arp_branches_outputs_allruns = []\n",
    "\n",
    "    for rundir in rundirs:\n",
    "        couple_branches_all_lines = arp_branches_allruns[rundir] \n",
    "        #couple_branches_all_lines is the item in the arp_branches_allruns dictionary for run****_****\n",
    "        timepoints = []\n",
    "        outputs = []\n",
    "\n",
    "        for line in couple_branches_all_lines:\n",
    "            line = line.strip()\n",
    "            if line.startswith('%'):\n",
    "                if line.startswith('% time'): #add the timepoint to the timepoints list, re-empty couples_arp_branch\n",
    "                    time = float(line.split(' ')[-1])\n",
    "                    timepoints.append(time)\n",
    "                    couples_arp_branch = {}\n",
    "                elif line.startswith('% end'): #make a dataframe from the dictionary of scal_prod values, append it to the outputs list\n",
    "                    df = pd.DataFrame.from_dict(couples_arp_branch, orient = 'index')\n",
    "                    outputs.append(df)\n",
    "            elif len(line.split()) > 0: #for lines with data in them, split the data into class, id, and scal_prod\n",
    "                [couple_class, couple_id, scal_prod] = line.split()\n",
    "                couples_arp_branch[int(couple_id)] = {'scal_prod' : float(scal_prod)}\n",
    "                #for the item in the dictionary called couple_id, add the scal_prod value\n",
    "\n",
    "        #concatenate all outputs dataframes (scal_prod values for a given timepoint) into a single dataframe with scal_prod values for all timepoints\n",
    "        all_outputs = pd.concat(outputs, keys = timepoints,\n",
    "                            names = ['time', 'id'])\n",
    "\n",
    "        #convert scal_prod values into a branch angle in degrees (scal_prod is dot product using unit vectors, so angle is cos-1(scal_prod)\n",
    "        all_outputs['branch_angle_deg'] = np.degrees(np.arccos(all_outputs['scal_prod']))\n",
    "        #add the outputs dataframe for the run to the list of dataframes for all runs\n",
    "        couple_arp_branches_outputs_allruns.append(all_outputs)\n",
    "        print( 'finished parsing ' + rundir)\n",
    "\n",
    "    #concatenate dataframes from each run into a single dataframe with values for all timepoints for all runs\n",
    "    all_couple_arp_branches = pd.concat(couple_arp_branches_outputs_allruns, keys = rundirs,\n",
    "                                  names = ['run', 'time', 'id'])\n",
    "\n",
    "    #merge the branching angle dataframe with the arp23 dataframe\n",
    "    #how=outer means that for the arps without information about branching, these arps are kept in the dataframe\n",
    "    all_arp_combined = pd.merge(all_couple_arp, all_couple_arp_branches, on = ['run','time', 'id'], how = 'outer')\n",
    "\n",
    "all_arp_combined.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "3fd48343",
   "metadata": {},
   "outputs": [],
   "source": [
    "if report_arp == 'yes':\n",
    "    if save_pickles=='yes':\n",
    "        all_arp_combined.to_pickle(output_dir+'/dataframes/arp_positions_angles.pkl')\n",
    "        bound_arp.to_pickle(output_dir+'/dataframes/bound_arp.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "73fd2e92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All done!\n",
      "Plot using CME_plotting_single_rungroup.ipynb, CME_plotting_multi_rungroup.ipynb, or CME_summary_plotting.ipynb\n"
     ]
    }
   ],
   "source": [
    "print('All done!')\n",
    "print('Plot using CME_plotting_single_rungroup.ipynb, CME_plotting_multi_rungroup.ipynb, or CME_summary_plotting.ipynb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d39ca4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
